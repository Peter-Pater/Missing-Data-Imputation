{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "alpha = 100\n",
    "epoch = 10000\n",
    "p_hint = 0.9\n",
    "miss_prob = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    return pd.read_csv(filename, sep=\",\").values\n",
    "\n",
    "def mask_data(data):\n",
    "    mask = np.random.binomial(n=1, p=1-miss_prob, size = data.shape)\n",
    "    return mask\n",
    "\n",
    "def normalize(data):\n",
    "    params = [np.nanmin(data, axis=0), np.nanmax(data, axis=0)]\n",
    "    data = (data - params[0] + 1e-6)/(params[1] - params[0] + 1e-6)\n",
    "    return data, params\n",
    "\n",
    "def denormalize(data, params):\n",
    "    data_back = data*(params[1] - params[0]) + params[0]\n",
    "    return data\n",
    "\n",
    "data = load_data(\"letter.csv\")\n",
    "data = np.array(data, dtype=np.float64)\n",
    "n,d = data.shape\n",
    "mask = mask_data(data)\n",
    "data_masked = np.copy(data)\n",
    "data_masked[mask == 0] = np.nan\n",
    "data_masked, params = normalize(data_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    value = np.random.normal(scale=1/np.sqrt((shape[0]/2)), size=shape)\n",
    "    return torch.tensor(value, requires_grad=True)\n",
    "\n",
    "def generator(X_tilde,M):\n",
    "    inputs = torch.cat([X_tilde,M], dim=1)\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)\n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3)\n",
    "    return G_prob\n",
    "\n",
    "def discriminator(X_hat,H):\n",
    "    inputs = torch.cat([X_hat,H], dim=1)\n",
    "    D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)\n",
    "    D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_prob = torch.sigmoid(torch.matmul(D_h2, D_W3) + D_b3)\n",
    "    return D_prob\n",
    "\n",
    "def discriminator_loss(X_tilde, M, H):\n",
    "    X_bar = generator(X_tilde, M)\n",
    "    X_hat = X_tilde * M + X_bar * (1-M)\n",
    "    M_hat = discriminator(X_hat, H)\n",
    "    loss_D = -torch.mean(M * torch.log(M_hat+1e-8) + (1-M) * torch.log(1-M_hat+1e-8))\n",
    "    return loss_D\n",
    "\n",
    "def generator_loss(X_tilde, M, H):\n",
    "    X_bar = generator(X_tilde, M)\n",
    "    X_hat = X_tilde * M + X_bar * (1-M)\n",
    "    M_hat = discriminator(X_hat, H)\n",
    "    loss_G_first = -torch.mean((1-M) * torch.log(M_hat+1e-8))\n",
    "    loss_G_second = torch.mean((M * X_tilde - M * X_bar)**2)/torch.mean(M)\n",
    "    loss_G = loss_G_first + alpha*loss_G_second\n",
    "    return loss_G, loss_G_second\n",
    "\n",
    "hidden_dim1 = d\n",
    "hidden_dim2 = d\n",
    "G_W1 = init_weights([d*2, hidden_dim1])\n",
    "G_b1 = torch.zeros([hidden_dim1,],requires_grad=True)\n",
    "G_W2 = init_weights([hidden_dim1, hidden_dim2])\n",
    "G_b2 = torch.zeros([hidden_dim2,],requires_grad=True)\n",
    "G_W3 = init_weights([hidden_dim2, d])\n",
    "G_b3 = torch.zeros([d,],requires_grad=True)\n",
    "optimizer_G = torch.optim.Adam([G_W1,G_b1,G_W2,G_b2,G_W3,G_b3])\n",
    "\n",
    "D_W1 = init_weights([d*2, hidden_dim1])\n",
    "D_b1 = torch.zeros([hidden_dim1,],requires_grad=True)\n",
    "D_W2 = init_weights([hidden_dim1, hidden_dim2])\n",
    "D_b2 = torch.zeros([hidden_dim2,],requires_grad=True)\n",
    "D_W3 = init_weights([hidden_dim2, d])\n",
    "D_b3 = torch.zeros([d,],requires_grad=True)\n",
    "optimizer_D = torch.optim.Adam([D_W1,D_b1,D_W2,D_b2,D_W3,D_b3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 500\tgenerator_loss: 1.715\n",
      "iteration: 1000\tgenerator_loss: 1.05\n",
      "iteration: 1500\tgenerator_loss: 0.9805\n",
      "iteration: 2000\tgenerator_loss: 0.8709\n",
      "iteration: 2500\tgenerator_loss: 0.8501\n",
      "iteration: 3000\tgenerator_loss: 0.7317\n",
      "iteration: 3500\tgenerator_loss: 0.6719\n",
      "iteration: 4000\tgenerator_loss: 0.6631\n",
      "iteration: 4500\tgenerator_loss: 0.6471\n",
      "iteration: 5000\tgenerator_loss: 0.58\n",
      "iteration: 5500\tgenerator_loss: 0.6049\n",
      "iteration: 6000\tgenerator_loss: 0.6158\n",
      "iteration: 6500\tgenerator_loss: 0.6471\n",
      "iteration: 7000\tgenerator_loss: 0.5594\n",
      "iteration: 7500\tgenerator_loss: 0.4999\n",
      "iteration: 8000\tgenerator_loss: 0.5149\n",
      "iteration: 8500\tgenerator_loss: 0.545\n",
      "iteration: 9000\tgenerator_loss: 0.4956\n",
      "iteration: 9500\tgenerator_loss: 0.4624\n",
      "iteration: 10000\tgenerator_loss: 0.5339\n",
      "0.12612935615963045\n"
     ]
    }
   ],
   "source": [
    "mask = 1-np.isnan(data_masked)\n",
    "data_masked[np.isnan(data_masked)] = 0.0\n",
    "\n",
    "for iteration in range(1,epoch+1):\n",
    "    batch_idx = np.random.choice(n,batch_size)\n",
    "    X_tilde = data_masked[batch_idx, :]\n",
    "    M = mask[batch_idx, :]\n",
    "    Z = np.random.uniform(0, 0.01, size = (batch_size,d))\n",
    "    B = np.random.binomial(n=1, p=p_hint, size = (batch_size,d))\n",
    "    H = M*B\n",
    "    X_tilde = M * X_tilde + (1-M) * Z\n",
    "    \n",
    "    X_tilde = torch.tensor(X_tilde, dtype=torch.float64)\n",
    "    M = torch.tensor(M, dtype=torch.float64)\n",
    "    H = torch.tensor(H, dtype=torch.float64)\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "    loss_D = discriminator_loss(X_tilde, M, H)\n",
    "    loss_D.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "    loss_G, loss_G_second = generator_loss(X_tilde, M, H)\n",
    "    loss_G.backward()\n",
    "    optimizer_G.step()\n",
    "    \n",
    "    if iteration % 500 == 0:\n",
    "        print('iteration: {}'.format(iteration),end='\\t')\n",
    "        print('generator_loss: {:.4}'.format(loss_G.item()),end='\\n')\n",
    "        \n",
    "        \n",
    "Z = np.random.uniform(0, 0.01, size = (n,d))\n",
    "X_tilde = mask*data_masked + (1-mask)*Z\n",
    "imputed = generator(torch.tensor(X_tilde), torch.tensor(mask))\n",
    "imputed = torch.tensor(data_masked) * torch.tensor(mask) + imputed * (1-torch.tensor(mask))\n",
    "imputed = imputed.detach().numpy()\n",
    "rmse = np.sqrt(np.sum(((1-mask)*imputed - (1-mask)*normalize(data)[0])**2)/np.sum(1-mask))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
